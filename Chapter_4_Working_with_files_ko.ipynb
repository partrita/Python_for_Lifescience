{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfN3m57r4l21X+jqb/mezs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ash100/Python_for_Lifescience/blob/main/Chapter_4_Working_with_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Colab에서 열기\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**생물학적 데이터 분석을 위한 파이썬 학습**\n",
        "## **4장:** 파일 작업\n",
        "\n",
        "이 강좌는 **Ashfaq Ahmad 박사님**께서 설계하고 강의하십니다. 강의 전반에 걸쳐 생명 과학 또는 생명 과학 분야의 예시들을 사용할 것입니다."
      ],
      "metadata": {
        "id": "4jtCrs4bgPir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 📅 강좌 개요\n",
        "\n",
        "---\n",
        "\n",
        "## 🏗️ 기초 (1-2주차)\n",
        "\n",
        "### 📘 1장: 파이썬과 Colab 시작하기\n",
        "- Google Colab 인터페이스 소개\n",
        "- 기본 파이썬 문법 및 데이터 타입\n",
        "- 변수, 문자열 및 기본 연산\n",
        "- 출력문과 주석\n",
        "\n",
        "### 📘 2장: 제어 구조\n",
        "- 조건문 (`if`/`else`)\n",
        "- 반복문 (`for` 및 `while`)\n",
        "- 기본 함수 및 범위\n",
        "\n",
        "---\n",
        "\n",
        "## 🧬 데이터 처리 (3-4주차)\n",
        "\n",
        "### 📘 3장: 생물학을 위한 데이터 구조\n",
        "- 리스트와 튜플 (서열, 실험 데이터 저장)\n",
        "- 딕셔너리 (유전자 주석, 종 데이터)\n",
        "- 세트 (고유 식별자, 샘플 모음)\n",
        "\n",
        "### 📘 4장: 파일 작업\n",
        "- 텍스트 파일 읽고 쓰기\n",
        "- CSV 파일 처리 (실험 데이터)\n",
        "- 생물학 데이터셋을 위한 기본 파일 작업\n",
        "\n",
        "---\n",
        "\n",
        "## 📊 과학 컴퓨팅 (5-7주차)\n",
        "\n",
        "### 📘 5장: 수치 데이터를 위한 NumPy\n",
        "- 배열을 이용한 실험 측정값 저장\n",
        "- 데이터셋에 대한 수학적 연산\n",
        "- 통계 계산 (평균, 중앙값, 표준편차)\n",
        "\n",
        "### 📘 6장: 데이터 분석을 위한 Pandas\n",
        "- 구조화된 생물학 데이터를 위한 데이터프레임\n",
        "- 데이터 정제 및 조작\n",
        "- 실험 결과 필터링 및 그룹화\n",
        "- 결측 데이터 처리\n",
        "\n",
        "### 📘 7장: 데이터 시각화\n",
        "- 과학적 플롯을 위한 Matplotlib 기초\n",
        "- 출판 품질의 그림 생성\n",
        "- 생물학 데이터를 위한 특수 플롯 (히스토그램, 산점도, 박스 플롯)\n",
        "\n",
        "---\n",
        "\n",
        "## 🔬 생물학적 응용 (8-10주차)\n",
        "\n",
        "### 📘 8장: 서열 분석\n",
        "- DNA/RNA 서열을 위한 문자열 조작\n",
        "- 기본 서열 연산 (역상보, 전사)\n",
        "- FASTA 파일 읽기\n",
        "- 간단한 서열 통계\n",
        "\n",
        "### 📘 9장: 생물학을 위한 통계 분석\n",
        "- 가설 검정 기초\n",
        "- t-검정 및 카이제곱 검정\n",
        "- 상관 관계 분석\n",
        "- `scipy.stats` 소개\n",
        "\n",
        "### 📘 10장: 실용적인 프로젝트\n",
        "- 유전자 발현 데이터 분석\n",
        "- 집단 유전학 계산\n",
        "- 생태 데이터 분석\n",
        "- 재현 가능한 연구 워크플로우 생성\n",
        "\n",
        "---\n",
        "\n",
        "## 🚀 고급 주제 *(선택 – 11-12주차)*\n",
        "\n",
        "### 📘 11장: 생물정보학 라이브러리\n",
        "- Biopython 소개\n",
        "- 생물학 데이터베이스 작업\n",
        "- 계통 발생 분석 기초\n",
        "\n",
        "### 📘 12장: 모범 사례\n",
        "- 코드 구성 및 문서화\n",
        "- 오류 처리\n",
        "- 재현 가능한 연구 관행\n",
        "- 코드 및 결과 공유\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 핵심 교수 전략\n",
        "\n",
        "1. 각 장을 생물학적 맥락으로 시작하십시오 – 프로그래밍 개념이 해당 분야에 왜 중요한지 설명하십시오.\n",
        "2. 전체에 걸쳐 생물학적 데이터셋을 사용하십시오 – 유전자 서열, 실험 측정값, 종 데이터.\n",
        "3. 각 개념 뒤에 실습 예제를 포함하십시오.\n",
        "4. 재현성을 강조하십시오 – 코드가 분석 과정을 어떻게 문서화하는지 보여주십시오.\n",
        "5. 복잡성을 점진적으로 구축하십시오 – 간단한 예제로 시작하여 실제 연구 시나리오로 나아가십시오.\n",
        "\n",
        "---\n",
        "\n",
        "✅ 이 과정은 기본적인 프로그래밍 개념에서 실용적인 생물학적 응용으로 나아가므로, 학생들이 배운 것을 연구 및 교과 과정에 즉시 적용할 수 있도록 보장합니다.\n"
      ],
      "metadata": {
        "id": "u1FI5JrPgZ7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 목표\n",
        "이 장이 끝나면 다음을 할 수 있게 됩니다:\n",
        "\n",
        "1. 생물학적 데이터가 포함된 텍스트 파일 읽기 및 쓰기\n",
        "2. 실험 데이터가 포함된 CSV 파일 처리\n",
        "3. 생물학적 데이터셋에 대한 기본 파일 작업 수행\n",
        "4. 실제 생물학적 시나리오에 파일 처리 기술 적용"
      ],
      "metadata": {
        "id": "1YnFa9ttgkKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **섹션 1:** 텍스트 파일 읽고 쓰기\n",
        "\n",
        "텍스트 파일은 데이터를 저장하고 검색하는 데 기본적입니다. 이 섹션에서는 기존 텍스트 파일에서 콘텐츠를 읽고 파이썬을 사용하여 새 콘텐츠를 쓰는 방법을 배웁니다.\n",
        "\n",
        "### 1.1 텍스트 파일 읽기\n",
        "\n",
        "파일 읽기에는 파일을 열고, 콘텐츠를 처리한 다음, 닫는 과정이 포함됩니다. 파이썬의 `open()` 함수는 파일을 여는 데 사용됩니다. 읽을 때 일반적으로 파일을 '읽기 모드'(`'r'`)로 엽니다.\n",
        "\n",
        "### 파일 열고 닫기\n",
        "\n",
        "파일 작업을 마친 후에는 시스템 리소스를 확보하기 위해 파일을 닫는 것이 중요합니다. `with` 문은 오류가 발생하더라도 파일이 자동으로 닫히도록 보장하므로 파일 작업을 처리하는 데 권장되는 방법입니다.\n",
        "\n",
        "**예제 1: 전체 파일 읽기**\n",
        "\n",
        "먼저 읽기를 시연하기 위해 더미 파일을 만들어 보겠습니다.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v93-p5OCqXBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dummy file for demonstration\n",
        "with open(\"sample.txt\", \"w\") as file:\n",
        "    file.write(\"Hello, this is line 1.\\n\")\n",
        "    file.write(\"This is line 2.\\n\")\n",
        "    file.write(\"And this is line 3.\")"
      ],
      "metadata": {
        "id": "BcBOjLYZkRb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let's read the entire content of 'sample.txt'\n",
        "with open(\"sample.txt\", \"r\") as file:\n",
        "    content = file.read()\n",
        "    print(\"Content of sample.txt:\")\n",
        "    print(content)"
      ],
      "metadata": {
        "id": "i86nwCuTkd64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 다양한 목적을 위한 파일 모드\n",
        "\n",
        "파이썬에서 파일로 작업할 때 `open()` 함수는 파일에 액세스하는 방법을 지정하는 `mode` 인수를 사용합니다. 이러한 모드를 이해하는 것은 의도하지 않은 부작용 없이 원하는 작업을 수행하는 데 중요합니다.\n",
        "\n",
        "| 모드 | 설명 | 파일이 있는 경우의 동작 | 파일이 없는 경우의 동작 |\n",
        "| :--- | :------------------------------------------------------------------------------------------------------ | :---------------------------------------------------- | :-------------------------------------------------- |\n",
        "| `'r'` | **읽기 전용**: 읽기 위해 파일을 엽니다. 파일 포인터는 파일의 시작 부분에 위치합니다. | 파일 내용이 보존되고, 처음부터 읽기 시작합니다. | `FileNotFoundError`를 발생시킵니다. |\n",
        "| `'w'` | **쓰기**: 쓰기 위해 파일을 엽니다. 파일이 있으면 내용이 잘립니다(지워집니다). | **내용이 덮어쓰여집니다.** | 새 빈 파일이 생성됩니다. |\n",
        "| `'a'` | **추가**: 추가하기 위해 파일을 엽니다. 새 데이터는 파일의 끝에 쓰여집니다. | 기존 내용의 끝에 새 내용이 추가됩니다. | 새 빈 파일이 생성됩니다. |\n",
        "| `'r+'` | **읽기 및 쓰기**: 읽고 쓰기 위해 파일을 엽니다. 파일 포인터는 시작 부분에 있습니다. | 파일 내용이 보존되고, 처음부터 읽고 쓸 수 있습니다. | `FileNotFoundError`를 발생시킵니다. |\n",
        "| `'x'` | **배타적 생성**: 배타적 생성을 위해 파일을 엽니다. 파일이 이미 있으면 작업이 실패합니다. | `FileExistsError`를 발생시킵니다. | 쓰기를 위한 새 빈 파일이 생성됩니다. |"
      ],
      "metadata": {
        "id": "P8tnxkfYiF4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample DNA sequence file\n",
        "sample_dna = \"\"\"ATCGATCGATCGATCGGCTAGCTAGCT\n",
        "AGCTATTAAGGCCTTAAGGCCCGATCGATCGATCGAT\"\"\"\n",
        "\n",
        "# Write to a file\n",
        "with open('sample_dna.txt', 'w') as file:\n",
        "    file.write(sample_dna)\n",
        "\n",
        "print(\"Sample DNA file created!\")"
      ],
      "metadata": {
        "id": "-SRktDVZx_O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**참고.**<br>삼중 따옴표를 사용하면 \\n이나 문자열 연결과 같은 특수 문자 없이도 문자열이 여러 줄에 걸쳐 있을 수 있습니다."
      ],
      "metadata": {
        "id": "c9sofvzll4ho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMq4FzUsgMsj"
      },
      "outputs": [],
      "source": [
        "# Read the entire file\n",
        "with open('sample_dna.txt', 'r') as file:\n",
        "    content = file.read()\n",
        "    print(\"File contents:\")\n",
        "    print(content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read line by line\n",
        "with open('sample_dna.txt', 'r') as file:\n",
        "    print(\"Reading line by line:\")\n",
        "    for line_number, line in enumerate(file, 1):\n",
        "        print(f\"Line {line_number}: {line.strip()}\")"
      ],
      "metadata": {
        "id": "4UCvnLoJbsi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 FASTA 파일 처리**"
      ],
      "metadata": {
        "id": "zqdUxcehfBtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample FASTA file\n",
        "fasta_content = \"\"\">seq1 Human hemoglobin alpha chain\n",
        "MVLSPADKTNVKAAWGKVGAHAGEYGAEALERMFLSFPTTKTYFPHFDLSHGSAQVKGHG\n",
        "KKVADALTNAVAHVDDMPNALSALSDLHAHKLRVDPVNFKLLSHCLLVTLAAHLPAEFTP\n",
        "AVHASLDKFLASVSTVLTSKYR\n",
        "\n",
        ">seq2 Human hemoglobin beta chain\n",
        "MVHLTPEEKSAVTALWGKVNVDEVGGEALGRLLVVYPWTQRFFESFGDLSTPDAVMGNPK\n",
        "VKAHGKKVLGAFSDGLAHLDNLKGTFATLSELHCDKLHVDPENFRLLGNVLVCVLAHHFG\n",
        "KEFTPPVQAAYQKVVAGVANALAHKYH\"\"\"\n",
        "\n",
        "with open('sample_sequences.fasta', 'w') as file:\n",
        "    file.write(fasta_content)\n",
        "\n",
        "print(\"FASTA file created!\")"
      ],
      "metadata": {
        "id": "G0MeBrHkq38X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래에서는 **FASTA** 파일을 파싱할 것입니다.\n",
        "### **FASTA를 파싱하는 이유?**\n",
        "\n",
        "종종 FASTA 파일에서 다음과 같은 특정 정보를 추출해야 합니다:\n",
        "* 시퀀스 헤더만.\n",
        "* 시퀀스 자체만.\n",
        "* 헤더를 해당 시퀀스에 매핑."
      ],
      "metadata": {
        "id": "7bF1ZStKm2S4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to parse FASTA file\n",
        "def parse_fasta(filename):\n",
        "    \"\"\"Parse a FASTA file and return sequences as a dictionary\"\"\"\n",
        "    sequences = {}\n",
        "    current_header = None\n",
        "    current_sequence = []\n",
        "\n",
        "    with open(filename, 'r') as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line.startswith('>'):\n",
        "                # Save previous sequence if exists\n",
        "                if current_header:\n",
        "                    sequences[current_header] = ''.join(current_sequence)\n",
        "                # Start new sequence\n",
        "                current_header = line[1:]  # Remove '>'\n",
        "                current_sequence = []\n",
        "            else:\n",
        "                current_sequence.append(line)\n",
        "\n",
        "        # Save last sequence\n",
        "        if current_header:\n",
        "            sequences[current_header] = ''.join(current_sequence)\n",
        "\n",
        "    return sequences\n",
        "\n",
        "# Parse the FASTA file\n",
        "sequences = parse_fasta('sample_sequences.fasta')\n",
        "\n",
        "# Display results\n",
        "for header, sequence in sequences.items():\n",
        "    print(f\"Header: {header}\")\n",
        "    print(f\"Sequence length: {len(sequence)}\")\n",
        "    print(f\"First 50 characters: {sequence[:50]}...\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "QkObT9OFfUOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 분석 결과 작성**"
      ],
      "metadata": {
        "id": "W7247obHrMmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze sequences and write results\n",
        "def analyze_sequence(sequence):\n",
        "    \"\"\"Analyze a DNA/protein sequence\"\"\"\n",
        "    analysis = {\n",
        "        'length': len(sequence),\n",
        "        'A_count': sequence.count('A'),\n",
        "        'T_count': sequence.count('T'),\n",
        "        'G_count': sequence.count('G'),\n",
        "        'C_count': sequence.count('C'),\n",
        "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence) * 100\n",
        "    }\n",
        "    return analysis\n",
        "\n",
        "# Analyze all sequences and write results\n",
        "with open('sequence_analysis.txt', 'w') as output_file:\n",
        "    output_file.write(\"Sequence Analysis Results\\n\")\n",
        "    output_file.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "    for header, sequence in sequences.items():\n",
        "        analysis = analyze_sequence(sequence)\n",
        "        output_file.write(f\"Sequence: {header}\\n\")\n",
        "        output_file.write(f\"Length: {analysis['length']} amino acids\\n\")\n",
        "        output_file.write(f\"Amino acid composition:\\n\")\n",
        "        output_file.write(f\"  A: {analysis['A_count']}\\n\")\n",
        "        output_file.write(f\"  T: {analysis['T_count']}\\n\")\n",
        "        output_file.write(f\"  G: {analysis['G_count']}\\n\")\n",
        "        output_file.write(f\"  C: {analysis['C_count']}\\n\")\n",
        "        output_file.write(f\"GC Content: {analysis['gc_content']:.2f}%\\n\")\n",
        "        output_file.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "print(\"Analysis complete! Results written to sequence_analysis.txt\")\n",
        "\n",
        "# Display the results\n",
        "with open('sequence_analysis.txt', 'r') as file:\n",
        "    print(file.read())"
      ],
      "metadata": {
        "id": "y24ZgiRxrNoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **섹션 2.** CSV 파일 처리 (실험 데이터)\n",
        "**2.1 기본 CSV 작업**\n",
        "\n",
        "CSV는 **Comma Separated Values**의 약자입니다. 표 형식 데이터(숫자 및 텍스트)를 구조화된 방식으로 저장하는 데 사용되는 간단한 일반 텍스트 파일 형식입니다. 파일의 각 줄은 데이터 레코드를 나타내며, 각 레코드는 쉼표로 구분된 하나 이상의 필드로 구성됩니다."
      ],
      "metadata": {
        "id": "YzvhQsUJrVH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dummy CSV file\n",
        "csv_data = \"\"\"Name,Age,City\n",
        "Alice,30,New York\n",
        "Bob,24,London\n",
        "Charlie,35,Paris\n",
        "David,28,\"San Francisco\"\n",
        "\"\"\"\n",
        "with open(\"people.csv\", \"w\") as f:\n",
        "    f.write(csv_data.strip())\n",
        "\n",
        "print(\"Created 'people.csv' for demonstration.\")"
      ],
      "metadata": {
        "id": "IPJxDZtdoWfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the above CSV file\n",
        "import csv\n",
        "\n",
        "print(\"\\nReading 'people.csv' with csv.reader:\")\n",
        "with open('people.csv', 'r', newline='') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    header = next(csv_reader) # Read the header row\n",
        "    print(f\"Header: {header}\")\n",
        "\n",
        "    for row in csv_reader:\n",
        "        print(f\"Row: {row}\")\n",
        "        # You can access elements by index, e.g., row[0] for Name, row[1] for Age\n",
        "        # print(f\"Name: {row[0]}, Age: {row[1]}, City: {row[2]}\")"
      ],
      "metadata": {
        "id": "ktg69-2nowY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Create sample experimental data\n",
        "experimental_data = [\n",
        "    ['Sample_ID', 'Treatment', 'Concentration', 'Growth_Rate', 'Viability'],\n",
        "    ['S001', 'Control', 0, 2.3, 98.5],\n",
        "    ['S002', 'Drug_A', 10, 1.8, 85.2],\n",
        "    ['S003', 'Drug_A', 50, 1.2, 72.1],\n",
        "    ['S004', 'Drug_A', 100, 0.8, 45.3],\n",
        "    ['S005', 'Drug_B', 10, 2.1, 92.1],\n",
        "    ['S006', 'Drug_B', 50, 1.5, 78.9],\n",
        "    ['S007', 'Drug_B', 100, 1.0, 55.7],\n",
        "    ['S008', 'Control', 0, 2.4, 97.8]\n",
        "]\n",
        "\n",
        "# Write to CSV file\n",
        "with open('experimental_data.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(experimental_data)\n",
        "\n",
        "print(\"Experimental data CSV created!\")"
      ],
      "metadata": {
        "id": "fsxhn2IerV6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and display CSV data\n",
        "with open('experimental_data.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    print(\"Experimental Data:\")\n",
        "    for row in reader:\n",
        "        print('\\t'.join(row))"
      ],
      "metadata": {
        "id": "UIW_DQhNf9Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2 DictReader를 사용하여 CSV 작업하기**"
      ],
      "metadata": {
        "id": "6iByDVX9gBBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`csv.DictReader` 클래스는 CSV 파일을 다룰 때, 특히 데이터에 명확한 헤더 행이 있을 때 매우 강력하고 권장되는 도구입니다. `row[0]`, `row[1]`과 같이 인덱스 번호를 기억해야 하는 문자열 목록을 제공하는 대신, `DictReader`는 각 행을 딕셔너리로 제공합니다. 이렇게 하면 코드가 훨씬 더 읽기 쉬워지고 열 순서가 변경될 경우 오류가 발생할 가능성이 줄어듭니다.\n",
        "\n",
        "### `DictReader`를 사용하는 이유\n",
        "\n",
        "* **가독성:** 인덱스(예: `row[0]`) 대신 열 이름(예: `row['Name']`)으로 데이터에 액세스합니다.\n",
        "* **유지 관리성:** 코드가 더 견고해집니다. CSV 파일에서 열이 재정렬되더라도 열 이름이 동일하게 유지되는 한 코드가 손상되지 않습니다.\n",
        "* **편의성:** 데이터를 키-값 쌍 형식으로 직접 제공하므로 작업하기가 더 쉬운 경우가 많습니다.\n",
        "\n",
        "### 1. `csv.DictReader`의 기본 사용법\n",
        "\n",
        "`DictReader`를 사용하려면 열린 파일 객체를 전달하기만 하면 됩니다. 첫 번째 행을 자동으로 헤더로 읽고 해당 값을 후속 행의 딕셔너리 키로 사용합니다."
      ],
      "metadata": {
        "id": "l2NF5d_dpZTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**experimental_data**를 전달해 보겠습니다."
      ],
      "metadata": {
        "id": "4bP8UOMqqJOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV as dictionaries\n",
        "with open('experimental_data.csv', 'r') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "\n",
        "    print(\"Data as dictionaries:\")\n",
        "    for row in reader:\n",
        "        print(f\"Sample {row['Sample_ID']}: {row['Treatment']} treatment\")\n",
        "        print(f\"  Concentration: {row['Concentration']} μM\")\n",
        "        print(f\"  Growth Rate: {row['Growth_Rate']} /hr\")\n",
        "        print(f\"  Viability: {row['Viability']}%\")\n",
        "        print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "Zctu0kKygFWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3 데이터 분석 및 필터링** <br>\n",
        "데이터 분석은 유용한 정보를 발견하고, 결론을 알리고, 의사 결정을 지원하는 것을 목표로 데이터를 검사, 정리, 변환 및 모델링하는 것을 포함합니다. 데이터 필터링은 특정 기준을 충족하는 데이터의 특정 하위 집합을 선택할 수 있도록 하는 이 작업의 핵심 부분입니다.\n",
        "\n",
        "### 1. 기본 필터링 및 분석 (파이썬 내장 기능 사용)\n",
        "\n",
        "전문 라이브러리를 사용하기 전에, 특히 `csv.DictReader`를 사용하여 CSV를 구문 분석한 경우 표준 파이썬 리스트와 딕셔너리를 사용하여 기본 작업을 수행하는 방법을 이해하는 것이 좋습니다."
      ],
      "metadata": {
        "id": "EsTAtfCegGX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure people.csv exists\n",
        "csv_data = \"\"\"Name,Age,City,Occupation,Salary\n",
        "Alice,30,New York,Engineer,75000\n",
        "Bob,24,London,Designer,60000\n",
        "Charlie,35,Paris,Manager,90000\n",
        "David,28,\"San Francisco\",Engineer,80000\n",
        "Eve,22,Berlin,Analyst,55000\n",
        "Frank,40,Tokyo,Manager,100000\n",
        "Grace,29,Sydney,Designer,62000\n",
        "\"\"\"\n",
        "with open(\"people.csv\", \"w\") as f:\n",
        "    f.write(csv_data.strip())\n",
        "\n",
        "print(\"Ensured 'people.csv' for demonstration.\")\n",
        "\n",
        "import csv\n",
        "\n",
        "# Load the data into a list of dictionaries\n",
        "people_data = []\n",
        "with open('people.csv', 'r', newline='') as file:\n",
        "    csv_dict_reader = csv.DictReader(file)\n",
        "    for row in csv_dict_reader:\n",
        "        # Convert numeric values from string to appropriate types\n",
        "        try:\n",
        "            row['Age'] = int(row['Age'])\n",
        "            row['Salary'] = int(row['Salary'])\n",
        "        except ValueError:\n",
        "            print(f\"Warning: Could not convert numeric values in row: {row}\")\n",
        "            continue # Skip row if conversion fails\n",
        "        people_data.append(row)\n",
        "\n",
        "print(\"\\nLoaded data (first 3 records):\")\n",
        "for i, person in enumerate(people_data[:3]):\n",
        "    print(person)\n",
        "    if i == 2: break"
      ],
      "metadata": {
        "id": "uFx1HatVrI5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze experimental data\n",
        "def analyze_experimental_data(filename):\n",
        "    \"\"\"Analyze experimental data from CSV file\"\"\"\n",
        "    treatments = {}\n",
        "\n",
        "    with open(filename, 'r') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "\n",
        "        for row in reader:\n",
        "            treatment = row['Treatment']\n",
        "            concentration = float(row['Concentration'])\n",
        "            growth_rate = float(row['Growth_Rate'])\n",
        "            viability = float(row['Viability'])\n",
        "\n",
        "            if treatment not in treatments:\n",
        "                treatments[treatment] = {\n",
        "                    'concentrations': [],\n",
        "                    'growth_rates': [],\n",
        "                    'viabilities': []\n",
        "                }\n",
        "\n",
        "            treatments[treatment]['concentrations'].append(concentration)\n",
        "            treatments[treatment]['growth_rates'].append(growth_rate)\n",
        "            treatments[treatment]['viabilities'].append(viability)\n",
        "\n",
        "    return treatments\n",
        "\n",
        "# Analyze the data\n",
        "results = analyze_experimental_data('experimental_data.csv')\n",
        "\n",
        "# Calculate statistics\n",
        "for treatment, data in results.items():\n",
        "    print(f\"\\nTreatment: {treatment}\")\n",
        "    print(f\"Number of samples: {len(data['growth_rates'])}\")\n",
        "    print(f\"Average growth rate: {sum(data['growth_rates'])/len(data['growth_rates']):.2f} /hr\")\n",
        "    print(f\"Average viability: {sum(data['viabilities'])/len(data['viabilities']):.2f}%\")\n",
        "    print(f\"Concentration range: {min(data['concentrations'])}-{max(data['concentrations'])} μM\")"
      ],
      "metadata": {
        "id": "IGGSdFxvgKoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4 처리된 데이터 쓰기**"
      ],
      "metadata": {
        "id": "vudF34_VgPZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process and write summary data\n",
        "summary_data = []\n",
        "summary_data.append(['Treatment', 'Sample_Count', 'Avg_Growth_Rate', 'Avg_Viability', 'Max_Concentration'])\n",
        "\n",
        "for treatment, data in results.items():\n",
        "    avg_growth = sum(data['growth_rates']) / len(data['growth_rates'])\n",
        "    avg_viability = sum(data['viabilities']) / len(data['viabilities'])\n",
        "    max_concentration = max(data['concentrations'])\n",
        "    sample_count = len(data['growth_rates'])\n",
        "\n",
        "    summary_data.append([treatment, sample_count, f\"{avg_growth:.2f}\", f\"{avg_viability:.2f}\", max_concentration])\n",
        "\n",
        "# Write summary to new CSV\n",
        "with open('treatment_summary.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(summary_data)\n",
        "\n",
        "print(\"Summary data written to treatment_summary.csv\")\n",
        "\n",
        "# Display summary\n",
        "with open('treatment_summary.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    print(\"\\nTreatment Summary:\")\n",
        "    for row in reader:\n",
        "        print('\\t'.join(row))"
      ],
      "metadata": {
        "id": "6Hz3DpsigSMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **섹션 3.** 생물학적 데이터셋을 위한 기본 파일 작업\n",
        "생물학적 데이터셋은 종종 다양한 파일 형식(예: FASTA, FASTQ, BAM, VCF, CSV, TSV)으로 제공되며 매우 클 수 있습니다. 이러한 파일을 효율적으로 처리하는 것은 생물 정보학 워크플로에 매우 중요합니다. 이 섹션에서는 생물학적 데이터에서 흔히 접하는 일반적인 작업에 초점을 맞춰 파이썬의 기본적인 파일 작업을 다룹니다.<br>\n",
        "**3.1 파일 시스템 작업**\n",
        "\n",
        "`os` `glob` 및 `shutil` 모듈은 파일 **존재** 확인, 파일 및 디렉터리 **이동**, **복사**, **삭제**와 같은 파일 시스템과 상호 작용하는 함수를 제공합니다."
      ],
      "metadata": {
        "id": "Fw54vdDEgZLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Create a directory structure for biological data\n",
        "directories = ['data', 'data/sequences', 'data/experiments', 'results']\n",
        "\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        print(f\"Created directory: {directory}\")\n",
        "\n",
        "# Move files to appropriate directories\n",
        "import shutil\n",
        "\n",
        "# Move sequence files\n",
        "if os.path.exists('sample_sequences.fasta'):\n",
        "    shutil.move('sample_sequences.fasta', 'data/sequences/')\n",
        "    print(\"Moved FASTA file to sequences directory\")\n",
        "\n",
        "if os.path.exists('sample_dna.txt'):\n",
        "    shutil.move('sample_dna.txt', 'data/sequences/')\n",
        "    print(\"Moved DNA file to sequences directory\")\n",
        "\n",
        "# Move experimental data\n",
        "if os.path.exists('experimental_data.csv'):\n",
        "    shutil.move('experimental_data.csv', 'data/experiments/')\n",
        "    print(\"Moved experimental data to experiments directory\")\n",
        "\n",
        "# Move results\n",
        "if os.path.exists('sequence_analysis.txt'):\n",
        "    shutil.move('sequence_analysis.txt', 'results/')\n",
        "    print(\"Moved analysis results to results directory\")\n",
        "\n",
        "if os.path.exists('treatment_summary.csv'):\n",
        "    shutil.move('treatment_summary.csv', 'results/')\n",
        "    print(\"Moved summary to results directory\")"
      ],
      "metadata": {
        "id": "CehFBg8ZgvMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 파일 일괄 처리**"
      ],
      "metadata": {
        "id": "Ro0w7JfFgzXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create multiple sequence files for batch processing\n",
        "sample_sequences = {\n",
        "    'gene1.fasta': '>gene1\\nATCGATCGATCGATCG\\nGCTAGCTAGCTAGCTA',\n",
        "    'gene2.fasta': '>gene2\\nTTAAGGCCTTAAGGCC\\nCGATCGATCGATCGAT',\n",
        "    'gene3.fasta': '>gene3\\nGGCCTTAAGGCCTTAA\\nATCGATCGATCGATCG'\n",
        "}\n",
        "\n",
        "# Write sample files\n",
        "for filename, content in sample_sequences.items():\n",
        "    with open(f'data/sequences/{filename}', 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "print(\"Created sample sequence files for batch processing\")"
      ],
      "metadata": {
        "id": "NBsIUndZgzuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch process all FASTA files\n",
        "def batch_process_fasta_files(directory):\n",
        "    \"\"\"Process all FASTA files in a directory\"\"\"\n",
        "    fasta_files = glob.glob(os.path.join(directory, '*.fasta'))\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for filepath in fasta_files:\n",
        "        filename = os.path.basename(filepath)\n",
        "        print(f\"Processing: {filename}\")\n",
        "\n",
        "        sequences = parse_fasta(filepath)\n",
        "\n",
        "        for header, sequence in sequences.items():\n",
        "            analysis = analyze_sequence(sequence)\n",
        "            results[filename] = {\n",
        "                'header': header,\n",
        "                'analysis': analysis\n",
        "            }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Process all FASTA files\n",
        "batch_results = batch_process_fasta_files('data/sequences/')\n",
        "\n",
        "# Write batch results\n",
        "with open('results/batch_analysis.txt', 'w') as output_file:\n",
        "    output_file.write(\"Batch Analysis Results\\n\")\n",
        "    output_file.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "    for filename, data in batch_results.items():\n",
        "        output_file.write(f\"File: {filename}\\n\")\n",
        "        output_file.write(f\"Sequence: {data['header']}\\n\")\n",
        "        analysis = data['analysis']\n",
        "        output_file.write(f\"Length: {analysis['length']} bp\\n\")\n",
        "        output_file.write(f\"GC Content: {analysis['gc_content']:.2f}%\\n\")\n",
        "        output_file.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "print(\"Batch analysis complete!\")"
      ],
      "metadata": {
        "id": "voN_s5g1g72A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3 오류 처리 및 파일 유효성 검사**"
      ],
      "metadata": {
        "id": "nqLpKtG3g_f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_file_reader(filename):\n",
        "    \"\"\"Safely read a file with error handling\"\"\"\n",
        "    try:\n",
        "        with open(filename, 'r') as file:\n",
        "            content = file.read()\n",
        "            return content\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{filename}' not found!\")\n",
        "        return None\n",
        "    except PermissionError:\n",
        "        print(f\"Error: Permission denied for file '{filename}'!\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file '{filename}': {e}\")\n",
        "        return None\n",
        "\n",
        "# Test error handling\n",
        "print(\"Testing error handling:\")\n",
        "content = safe_file_reader('nonexistent_file.txt')\n",
        "print(f\"Content: {content}\")\n",
        "\n",
        "# Test with existing file\n",
        "content = safe_file_reader('results/batch_analysis.txt')\n",
        "if content:\n",
        "    print(f\"Successfully read file. Length: {len(content)} characters\")"
      ],
      "metadata": {
        "id": "LcJUxr7nhBxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.4 파일 정보 및 통계**"
      ],
      "metadata": {
        "id": "lOkDlHpZhGM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_info(filepath):\n",
        "    \"\"\"Get information about a file\"\"\"\n",
        "    try:\n",
        "        stats = os.stat(filepath)\n",
        "        return {\n",
        "            'size': stats.st_size,\n",
        "            'modified': stats.st_mtime,\n",
        "            'exists': True\n",
        "        }\n",
        "    except:\n",
        "        return {'exists': False}\n",
        "\n",
        "# Get information about all files in results directory\n",
        "results_files = glob.glob('results/*')\n",
        "\n",
        "print(\"File Information:\")\n",
        "print(\"=\" * 50)\n",
        "for filepath in results_files:\n",
        "    info = get_file_info(filepath)\n",
        "    if info['exists']:\n",
        "        filename = os.path.basename(filepath)\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"  Size: {info['size']} bytes\")\n",
        "        print(f\"  Modified: {info['modified']}\")\n",
        "        print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "b9cPU82XhKSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. 실습 문제\n",
        "**연습 문제 1: 유전자 발현 데이터 처리**"
      ],
      "metadata": {
        "id": "s_S05L4ehN9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample gene expression data\n",
        "gene_expression_data = [\n",
        "    ['Gene_ID', 'Gene_Name', 'Control_1', 'Control_2', 'Treatment_1', 'Treatment_2'],\n",
        "    ['G001', 'GAPDH', 1000, 1050, 980, 1020],\n",
        "    ['G002', 'ACTB', 800, 820, 750, 780],\n",
        "    ['G003', 'TP53', 200, 180, 450, 420],\n",
        "    ['G004', 'BRCA1', 150, 160, 300, 280],\n",
        "    ['G005', 'MYC', 300, 280, 150, 170]\n",
        "]\n",
        "\n",
        "with open('data/experiments/gene_expression.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(gene_expression_data)\n",
        "\n",
        "print(\"Gene expression data created!\")"
      ],
      "metadata": {
        "id": "qEhnccbkhVTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**과제:** 각 유전자의 발현 변화량을 계산하고 유의하게 변화한 유전자를 식별하는 함수를 작성하십시오."
      ],
      "metadata": {
        "id": "ZfufjCdyhdY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**연습 문제 2: 시퀀스 데이터의 품질 관리**"
      ],
      "metadata": {
        "id": "roe_cnIRhjgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sequence with quality issues\n",
        "problematic_sequences = \"\"\">seq_with_N\n",
        "ATCGATCGATCNNNGATCGATCG\n",
        ">short_seq\n",
        "ATCG\n",
        ">seq_with_gaps\n",
        "ATCGATCG---ATCGATCG\n",
        ">normal_seq\n",
        "ATCGATCGATCGATCGATCG\"\"\"\n",
        "\n",
        "with open('data/sequences/quality_check.fasta', 'w') as file:\n",
        "    file.write(problematic_sequences)\n",
        "\n",
        "print(\"Quality check sequences created!\")"
      ],
      "metadata": {
        "id": "8EnKE6oXhc2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**과제:** 문제가 있는 시퀀스를 식별하고 보고하는 품질 관리 함수를 작성하십시오."
      ],
      "metadata": {
        "id": "KLtoNEnNhzVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**요약**<br>\n",
        "이 장에서 배운 내용:\n",
        "\n",
        "**1. 텍스트 파일 작업:** FASTA와 같은 생물학적 데이터 형식을 포함한 텍스트 파일 읽기 및 쓰기 방법<br>\n",
        "**2. CSV 파일 처리:** 파이썬의 csv 모듈을 사용하여 CSV 형식의 실험 데이터 작업<br>\n",
        "**3. 파일 시스템 작업:** 디렉토리 및 일괄 처리로 생물학적 데이터셋 구성<br>\n",
        "**4. 오류 처리:** 적절한 오류 처리로 강력한 파일 작업 구현<br>\n",
        "**5. 모범 사례:** 생물학적 데이터 분석에서 파일 처리를 위한 파이썬 규칙 준수<br>\n",
        "\n",
        "이러한 기술은 생물학적 데이터셋으로 작업하기 위한 기초를 형성하며 더 고급 데이터 분석 작업에 필수적입니다."
      ],
      "metadata": {
        "id": "srDAnB17ijAW"
      }
    }
  ]
}
