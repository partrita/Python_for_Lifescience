{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfN3m57r4l21X+jqb/mezs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ash100/Python_for_Lifescience/blob/main/Chapter_4_Working_with_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Colabì—ì„œ ì—´ê¸°\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**ìƒë¬¼í•™ì  ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ íŒŒì´ì¬ í•™ìŠµ**\n",
        "## **4ì¥:** íŒŒì¼ ì‘ì—…\n",
        "\n",
        "ì´ ê°•ì¢ŒëŠ” **Ashfaq Ahmad ë°•ì‚¬ë‹˜**ê»˜ì„œ ì„¤ê³„í•˜ê³  ê°•ì˜í•˜ì‹­ë‹ˆë‹¤. ê°•ì˜ ì „ë°˜ì— ê±¸ì³ ìƒëª… ê³¼í•™ ë˜ëŠ” ìƒëª… ê³¼í•™ ë¶„ì•¼ì˜ ì˜ˆì‹œë“¤ì„ ì‚¬ìš©í•  ê²ƒì…ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "4jtCrs4bgPir"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ“… ê°•ì¢Œ ê°œìš”\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ—ï¸ ê¸°ì´ˆ (1-2ì£¼ì°¨)\n",
        "\n",
        "### ğŸ“˜ 1ì¥: íŒŒì´ì¬ê³¼ Colab ì‹œì‘í•˜ê¸°\n",
        "- Google Colab ì¸í„°í˜ì´ìŠ¤ ì†Œê°œ\n",
        "- ê¸°ë³¸ íŒŒì´ì¬ ë¬¸ë²• ë° ë°ì´í„° íƒ€ì…\n",
        "- ë³€ìˆ˜, ë¬¸ìì—´ ë° ê¸°ë³¸ ì—°ì‚°\n",
        "- ì¶œë ¥ë¬¸ê³¼ ì£¼ì„\n",
        "\n",
        "### ğŸ“˜ 2ì¥: ì œì–´ êµ¬ì¡°\n",
        "- ì¡°ê±´ë¬¸ (`if`/`else`)\n",
        "- ë°˜ë³µë¬¸ (`for` ë° `while`)\n",
        "- ê¸°ë³¸ í•¨ìˆ˜ ë° ë²”ìœ„\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§¬ ë°ì´í„° ì²˜ë¦¬ (3-4ì£¼ì°¨)\n",
        "\n",
        "### ğŸ“˜ 3ì¥: ìƒë¬¼í•™ì„ ìœ„í•œ ë°ì´í„° êµ¬ì¡°\n",
        "- ë¦¬ìŠ¤íŠ¸ì™€ íŠœí”Œ (ì„œì—´, ì‹¤í—˜ ë°ì´í„° ì €ì¥)\n",
        "- ë”•ì…”ë„ˆë¦¬ (ìœ ì „ì ì£¼ì„, ì¢… ë°ì´í„°)\n",
        "- ì„¸íŠ¸ (ê³ ìœ  ì‹ë³„ì, ìƒ˜í”Œ ëª¨ìŒ)\n",
        "\n",
        "### ğŸ“˜ 4ì¥: íŒŒì¼ ì‘ì—…\n",
        "- í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê³  ì“°ê¸°\n",
        "- CSV íŒŒì¼ ì²˜ë¦¬ (ì‹¤í—˜ ë°ì´í„°)\n",
        "- ìƒë¬¼í•™ ë°ì´í„°ì…‹ì„ ìœ„í•œ ê¸°ë³¸ íŒŒì¼ ì‘ì—…\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“Š ê³¼í•™ ì»´í“¨íŒ… (5-7ì£¼ì°¨)\n",
        "\n",
        "### ğŸ“˜ 5ì¥: ìˆ˜ì¹˜ ë°ì´í„°ë¥¼ ìœ„í•œ NumPy\n",
        "- ë°°ì—´ì„ ì´ìš©í•œ ì‹¤í—˜ ì¸¡ì •ê°’ ì €ì¥\n",
        "- ë°ì´í„°ì…‹ì— ëŒ€í•œ ìˆ˜í•™ì  ì—°ì‚°\n",
        "- í†µê³„ ê³„ì‚° (í‰ê· , ì¤‘ì•™ê°’, í‘œì¤€í¸ì°¨)\n",
        "\n",
        "### ğŸ“˜ 6ì¥: ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ Pandas\n",
        "- êµ¬ì¡°í™”ëœ ìƒë¬¼í•™ ë°ì´í„°ë¥¼ ìœ„í•œ ë°ì´í„°í”„ë ˆì„\n",
        "- ë°ì´í„° ì •ì œ ë° ì¡°ì‘\n",
        "- ì‹¤í—˜ ê²°ê³¼ í•„í„°ë§ ë° ê·¸ë£¹í™”\n",
        "- ê²°ì¸¡ ë°ì´í„° ì²˜ë¦¬\n",
        "\n",
        "### ğŸ“˜ 7ì¥: ë°ì´í„° ì‹œê°í™”\n",
        "- ê³¼í•™ì  í”Œë¡¯ì„ ìœ„í•œ Matplotlib ê¸°ì´ˆ\n",
        "- ì¶œíŒ í’ˆì§ˆì˜ ê·¸ë¦¼ ìƒì„±\n",
        "- ìƒë¬¼í•™ ë°ì´í„°ë¥¼ ìœ„í•œ íŠ¹ìˆ˜ í”Œë¡¯ (íˆìŠ¤í† ê·¸ë¨, ì‚°ì ë„, ë°•ìŠ¤ í”Œë¡¯)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¬ ìƒë¬¼í•™ì  ì‘ìš© (8-10ì£¼ì°¨)\n",
        "\n",
        "### ğŸ“˜ 8ì¥: ì„œì—´ ë¶„ì„\n",
        "- DNA/RNA ì„œì—´ì„ ìœ„í•œ ë¬¸ìì—´ ì¡°ì‘\n",
        "- ê¸°ë³¸ ì„œì—´ ì—°ì‚° (ì—­ìƒë³´, ì „ì‚¬)\n",
        "- FASTA íŒŒì¼ ì½ê¸°\n",
        "- ê°„ë‹¨í•œ ì„œì—´ í†µê³„\n",
        "\n",
        "### ğŸ“˜ 9ì¥: ìƒë¬¼í•™ì„ ìœ„í•œ í†µê³„ ë¶„ì„\n",
        "- ê°€ì„¤ ê²€ì • ê¸°ì´ˆ\n",
        "- t-ê²€ì • ë° ì¹´ì´ì œê³± ê²€ì •\n",
        "- ìƒê´€ ê´€ê³„ ë¶„ì„\n",
        "- `scipy.stats` ì†Œê°œ\n",
        "\n",
        "### ğŸ“˜ 10ì¥: ì‹¤ìš©ì ì¸ í”„ë¡œì íŠ¸\n",
        "- ìœ ì „ì ë°œí˜„ ë°ì´í„° ë¶„ì„\n",
        "- ì§‘ë‹¨ ìœ ì „í•™ ê³„ì‚°\n",
        "- ìƒíƒœ ë°ì´í„° ë¶„ì„\n",
        "- ì¬í˜„ ê°€ëŠ¥í•œ ì—°êµ¬ ì›Œí¬í”Œë¡œìš° ìƒì„±\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸš€ ê³ ê¸‰ ì£¼ì œ *(ì„ íƒ â€“ 11-12ì£¼ì°¨)*\n",
        "\n",
        "### ğŸ“˜ 11ì¥: ìƒë¬¼ì •ë³´í•™ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "- Biopython ì†Œê°œ\n",
        "- ìƒë¬¼í•™ ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…\n",
        "- ê³„í†µ ë°œìƒ ë¶„ì„ ê¸°ì´ˆ\n",
        "\n",
        "### ğŸ“˜ 12ì¥: ëª¨ë²” ì‚¬ë¡€\n",
        "- ì½”ë“œ êµ¬ì„± ë° ë¬¸ì„œí™”\n",
        "- ì˜¤ë¥˜ ì²˜ë¦¬\n",
        "- ì¬í˜„ ê°€ëŠ¥í•œ ì—°êµ¬ ê´€í–‰\n",
        "- ì½”ë“œ ë° ê²°ê³¼ ê³µìœ \n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  í•µì‹¬ êµìˆ˜ ì „ëµ\n",
        "\n",
        "1. ê° ì¥ì„ ìƒë¬¼í•™ì  ë§¥ë½ìœ¼ë¡œ ì‹œì‘í•˜ì‹­ì‹œì˜¤ â€“ í”„ë¡œê·¸ë˜ë° ê°œë…ì´ í•´ë‹¹ ë¶„ì•¼ì— ì™œ ì¤‘ìš”í•œì§€ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.\n",
        "2. ì „ì²´ì— ê±¸ì³ ìƒë¬¼í•™ì  ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤ â€“ ìœ ì „ì ì„œì—´, ì‹¤í—˜ ì¸¡ì •ê°’, ì¢… ë°ì´í„°.\n",
        "3. ê° ê°œë… ë’¤ì— ì‹¤ìŠµ ì˜ˆì œë¥¼ í¬í•¨í•˜ì‹­ì‹œì˜¤.\n",
        "4. ì¬í˜„ì„±ì„ ê°•ì¡°í•˜ì‹­ì‹œì˜¤ â€“ ì½”ë“œê°€ ë¶„ì„ ê³¼ì •ì„ ì–´ë–»ê²Œ ë¬¸ì„œí™”í•˜ëŠ”ì§€ ë³´ì—¬ì£¼ì‹­ì‹œì˜¤.\n",
        "5. ë³µì¡ì„±ì„ ì ì§„ì ìœ¼ë¡œ êµ¬ì¶•í•˜ì‹­ì‹œì˜¤ â€“ ê°„ë‹¨í•œ ì˜ˆì œë¡œ ì‹œì‘í•˜ì—¬ ì‹¤ì œ ì—°êµ¬ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ë‚˜ì•„ê°€ì‹­ì‹œì˜¤.\n",
        "\n",
        "---\n",
        "\n",
        "âœ… ì´ ê³¼ì •ì€ ê¸°ë³¸ì ì¸ í”„ë¡œê·¸ë˜ë° ê°œë…ì—ì„œ ì‹¤ìš©ì ì¸ ìƒë¬¼í•™ì  ì‘ìš©ìœ¼ë¡œ ë‚˜ì•„ê°€ë¯€ë¡œ, í•™ìƒë“¤ì´ ë°°ìš´ ê²ƒì„ ì—°êµ¬ ë° êµê³¼ ê³¼ì •ì— ì¦‰ì‹œ ì ìš©í•  ìˆ˜ ìˆë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.\n"
      ],
      "metadata": {
        "id": "u1FI5JrPgZ7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## í•™ìŠµ ëª©í‘œ\n",
        "ì´ ì¥ì´ ëë‚˜ë©´ ë‹¤ìŒì„ í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤:\n",
        "\n",
        "1. ìƒë¬¼í•™ì  ë°ì´í„°ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ë° ì“°ê¸°\n",
        "2. ì‹¤í—˜ ë°ì´í„°ê°€ í¬í•¨ëœ CSV íŒŒì¼ ì²˜ë¦¬\n",
        "3. ìƒë¬¼í•™ì  ë°ì´í„°ì…‹ì— ëŒ€í•œ ê¸°ë³¸ íŒŒì¼ ì‘ì—… ìˆ˜í–‰\n",
        "4. ì‹¤ì œ ìƒë¬¼í•™ì  ì‹œë‚˜ë¦¬ì˜¤ì— íŒŒì¼ ì²˜ë¦¬ ê¸°ìˆ  ì ìš©"
      ],
      "metadata": {
        "id": "1YnFa9ttgkKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ì„¹ì…˜ 1:** í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê³  ì“°ê¸°\n",
        "\n",
        "í…ìŠ¤íŠ¸ íŒŒì¼ì€ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ë° ê¸°ë³¸ì ì…ë‹ˆë‹¤. ì´ ì„¹ì…˜ì—ì„œëŠ” ê¸°ì¡´ í…ìŠ¤íŠ¸ íŒŒì¼ì—ì„œ ì½˜í…ì¸ ë¥¼ ì½ê³  íŒŒì´ì¬ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆ ì½˜í…ì¸ ë¥¼ ì“°ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
        "\n",
        "### 1.1 í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°\n",
        "\n",
        "íŒŒì¼ ì½ê¸°ì—ëŠ” íŒŒì¼ì„ ì—´ê³ , ì½˜í…ì¸ ë¥¼ ì²˜ë¦¬í•œ ë‹¤ìŒ, ë‹«ëŠ” ê³¼ì •ì´ í¬í•¨ë©ë‹ˆë‹¤. íŒŒì´ì¬ì˜ `open()` í•¨ìˆ˜ëŠ” íŒŒì¼ì„ ì—¬ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. ì½ì„ ë•Œ ì¼ë°˜ì ìœ¼ë¡œ íŒŒì¼ì„ 'ì½ê¸° ëª¨ë“œ'(`'r'`)ë¡œ ì—½ë‹ˆë‹¤.\n",
        "\n",
        "### íŒŒì¼ ì—´ê³  ë‹«ê¸°\n",
        "\n",
        "íŒŒì¼ ì‘ì—…ì„ ë§ˆì¹œ í›„ì—ëŠ” ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ë¥¼ í™•ë³´í•˜ê¸° ìœ„í•´ íŒŒì¼ì„ ë‹«ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. `with` ë¬¸ì€ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë”ë¼ë„ íŒŒì¼ì´ ìë™ìœ¼ë¡œ ë‹«íˆë„ë¡ ë³´ì¥í•˜ë¯€ë¡œ íŒŒì¼ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” ë° ê¶Œì¥ë˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì˜ˆì œ 1: ì „ì²´ íŒŒì¼ ì½ê¸°**\n",
        "\n",
        "ë¨¼ì € ì½ê¸°ë¥¼ ì‹œì—°í•˜ê¸° ìœ„í•´ ë”ë¯¸ íŒŒì¼ì„ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "v93-p5OCqXBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dummy file for demonstration\n",
        "with open(\"sample.txt\", \"w\") as file:\n",
        "    file.write(\"Hello, this is line 1.\\n\")\n",
        "    file.write(\"This is line 2.\\n\")\n",
        "    file.write(\"And this is line 3.\")"
      ],
      "metadata": {
        "id": "BcBOjLYZkRb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let's read the entire content of 'sample.txt'\n",
        "with open(\"sample.txt\", \"r\") as file:\n",
        "    content = file.read()\n",
        "    print(\"Content of sample.txt:\")\n",
        "    print(content)"
      ],
      "metadata": {
        "id": "i86nwCuTkd64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ë‹¤ì–‘í•œ ëª©ì ì„ ìœ„í•œ íŒŒì¼ ëª¨ë“œ\n",
        "\n",
        "íŒŒì´ì¬ì—ì„œ íŒŒì¼ë¡œ ì‘ì—…í•  ë•Œ `open()` í•¨ìˆ˜ëŠ” íŒŒì¼ì— ì•¡ì„¸ìŠ¤í•˜ëŠ” ë°©ë²•ì„ ì§€ì •í•˜ëŠ” `mode` ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ëª¨ë“œë¥¼ ì´í•´í•˜ëŠ” ê²ƒì€ ì˜ë„í•˜ì§€ ì•Šì€ ë¶€ì‘ìš© ì—†ì´ ì›í•˜ëŠ” ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë° ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
        "\n",
        "| ëª¨ë“œ | ì„¤ëª… | íŒŒì¼ì´ ìˆëŠ” ê²½ìš°ì˜ ë™ì‘ | íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°ì˜ ë™ì‘ |\n",
        "| :--- | :------------------------------------------------------------------------------------------------------ | :---------------------------------------------------- | :-------------------------------------------------- |\n",
        "| `'r'` | **ì½ê¸° ì „ìš©**: ì½ê¸° ìœ„í•´ íŒŒì¼ì„ ì—½ë‹ˆë‹¤. íŒŒì¼ í¬ì¸í„°ëŠ” íŒŒì¼ì˜ ì‹œì‘ ë¶€ë¶„ì— ìœ„ì¹˜í•©ë‹ˆë‹¤. | íŒŒì¼ ë‚´ìš©ì´ ë³´ì¡´ë˜ê³ , ì²˜ìŒë¶€í„° ì½ê¸° ì‹œì‘í•©ë‹ˆë‹¤. | `FileNotFoundError`ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤. |\n",
        "| `'w'` | **ì“°ê¸°**: ì“°ê¸° ìœ„í•´ íŒŒì¼ì„ ì—½ë‹ˆë‹¤. íŒŒì¼ì´ ìˆìœ¼ë©´ ë‚´ìš©ì´ ì˜ë¦½ë‹ˆë‹¤(ì§€ì›Œì§‘ë‹ˆë‹¤). | **ë‚´ìš©ì´ ë®ì–´ì“°ì—¬ì§‘ë‹ˆë‹¤.** | ìƒˆ ë¹ˆ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤. |\n",
        "| `'a'` | **ì¶”ê°€**: ì¶”ê°€í•˜ê¸° ìœ„í•´ íŒŒì¼ì„ ì—½ë‹ˆë‹¤. ìƒˆ ë°ì´í„°ëŠ” íŒŒì¼ì˜ ëì— ì“°ì—¬ì§‘ë‹ˆë‹¤. | ê¸°ì¡´ ë‚´ìš©ì˜ ëì— ìƒˆ ë‚´ìš©ì´ ì¶”ê°€ë©ë‹ˆë‹¤. | ìƒˆ ë¹ˆ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤. |\n",
        "| `'r+'` | **ì½ê¸° ë° ì“°ê¸°**: ì½ê³  ì“°ê¸° ìœ„í•´ íŒŒì¼ì„ ì—½ë‹ˆë‹¤. íŒŒì¼ í¬ì¸í„°ëŠ” ì‹œì‘ ë¶€ë¶„ì— ìˆìŠµë‹ˆë‹¤. | íŒŒì¼ ë‚´ìš©ì´ ë³´ì¡´ë˜ê³ , ì²˜ìŒë¶€í„° ì½ê³  ì“¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. | `FileNotFoundError`ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤. |\n",
        "| `'x'` | **ë°°íƒ€ì  ìƒì„±**: ë°°íƒ€ì  ìƒì„±ì„ ìœ„í•´ íŒŒì¼ì„ ì—½ë‹ˆë‹¤. íŒŒì¼ì´ ì´ë¯¸ ìˆìœ¼ë©´ ì‘ì—…ì´ ì‹¤íŒ¨í•©ë‹ˆë‹¤. | `FileExistsError`ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤. | ì“°ê¸°ë¥¼ ìœ„í•œ ìƒˆ ë¹ˆ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤. |"
      ],
      "metadata": {
        "id": "P8tnxkfYiF4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample DNA sequence file\n",
        "sample_dna = \"\"\"ATCGATCGATCGATCGGCTAGCTAGCT\n",
        "AGCTATTAAGGCCTTAAGGCCCGATCGATCGATCGAT\"\"\"\n",
        "\n",
        "# Write to a file\n",
        "with open('sample_dna.txt', 'w') as file:\n",
        "    file.write(sample_dna)\n",
        "\n",
        "print(\"Sample DNA file created!\")"
      ],
      "metadata": {
        "id": "-SRktDVZx_O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ì°¸ê³ .**<br>ì‚¼ì¤‘ ë”°ì˜´í‘œë¥¼ ì‚¬ìš©í•˜ë©´ \\nì´ë‚˜ ë¬¸ìì—´ ì—°ê²°ê³¼ ê°™ì€ íŠ¹ìˆ˜ ë¬¸ì ì—†ì´ë„ ë¬¸ìì—´ì´ ì—¬ëŸ¬ ì¤„ì— ê±¸ì³ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "c9sofvzll4ho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMq4FzUsgMsj"
      },
      "outputs": [],
      "source": [
        "# Read the entire file\n",
        "with open('sample_dna.txt', 'r') as file:\n",
        "    content = file.read()\n",
        "    print(\"File contents:\")\n",
        "    print(content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read line by line\n",
        "with open('sample_dna.txt', 'r') as file:\n",
        "    print(\"Reading line by line:\")\n",
        "    for line_number, line in enumerate(file, 1):\n",
        "        print(f\"Line {line_number}: {line.strip()}\")"
      ],
      "metadata": {
        "id": "4UCvnLoJbsi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 FASTA íŒŒì¼ ì²˜ë¦¬**"
      ],
      "metadata": {
        "id": "zqdUxcehfBtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample FASTA file\n",
        "fasta_content = \"\"\">seq1 Human hemoglobin alpha chain\n",
        "MVLSPADKTNVKAAWGKVGAHAGEYGAEALERMFLSFPTTKTYFPHFDLSHGSAQVKGHG\n",
        "KKVADALTNAVAHVDDMPNALSALSDLHAHKLRVDPVNFKLLSHCLLVTLAAHLPAEFTP\n",
        "AVHASLDKFLASVSTVLTSKYR\n",
        "\n",
        ">seq2 Human hemoglobin beta chain\n",
        "MVHLTPEEKSAVTALWGKVNVDEVGGEALGRLLVVYPWTQRFFESFGDLSTPDAVMGNPK\n",
        "VKAHGKKVLGAFSDGLAHLDNLKGTFATLSELHCDKLHVDPENFRLLGNVLVCVLAHHFG\n",
        "KEFTPPVQAAYQKVVAGVANALAHKYH\"\"\"\n",
        "\n",
        "with open('sample_sequences.fasta', 'w') as file:\n",
        "    file.write(fasta_content)\n",
        "\n",
        "print(\"FASTA file created!\")"
      ],
      "metadata": {
        "id": "G0MeBrHkq38X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì•„ë˜ì—ì„œëŠ” **FASTA** íŒŒì¼ì„ íŒŒì‹±í•  ê²ƒì…ë‹ˆë‹¤.\n",
        "### **FASTAë¥¼ íŒŒì‹±í•˜ëŠ” ì´ìœ ?**\n",
        "\n",
        "ì¢…ì¢… FASTA íŒŒì¼ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì • ì •ë³´ë¥¼ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤:\n",
        "* ì‹œí€€ìŠ¤ í—¤ë”ë§Œ.\n",
        "* ì‹œí€€ìŠ¤ ìì²´ë§Œ.\n",
        "* í—¤ë”ë¥¼ í•´ë‹¹ ì‹œí€€ìŠ¤ì— ë§¤í•‘."
      ],
      "metadata": {
        "id": "7bF1ZStKm2S4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to parse FASTA file\n",
        "def parse_fasta(filename):\n",
        "    \"\"\"Parse a FASTA file and return sequences as a dictionary\"\"\"\n",
        "    sequences = {}\n",
        "    current_header = None\n",
        "    current_sequence = []\n",
        "\n",
        "    with open(filename, 'r') as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if line.startswith('>'):\n",
        "                # Save previous sequence if exists\n",
        "                if current_header:\n",
        "                    sequences[current_header] = ''.join(current_sequence)\n",
        "                # Start new sequence\n",
        "                current_header = line[1:]  # Remove '>'\n",
        "                current_sequence = []\n",
        "            else:\n",
        "                current_sequence.append(line)\n",
        "\n",
        "        # Save last sequence\n",
        "        if current_header:\n",
        "            sequences[current_header] = ''.join(current_sequence)\n",
        "\n",
        "    return sequences\n",
        "\n",
        "# Parse the FASTA file\n",
        "sequences = parse_fasta('sample_sequences.fasta')\n",
        "\n",
        "# Display results\n",
        "for header, sequence in sequences.items():\n",
        "    print(f\"Header: {header}\")\n",
        "    print(f\"Sequence length: {len(sequence)}\")\n",
        "    print(f\"First 50 characters: {sequence[:50]}...\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "QkObT9OFfUOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 ë¶„ì„ ê²°ê³¼ ì‘ì„±**"
      ],
      "metadata": {
        "id": "W7247obHrMmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze sequences and write results\n",
        "def analyze_sequence(sequence):\n",
        "    \"\"\"Analyze a DNA/protein sequence\"\"\"\n",
        "    analysis = {\n",
        "        'length': len(sequence),\n",
        "        'A_count': sequence.count('A'),\n",
        "        'T_count': sequence.count('T'),\n",
        "        'G_count': sequence.count('G'),\n",
        "        'C_count': sequence.count('C'),\n",
        "        'gc_content': (sequence.count('G') + sequence.count('C')) / len(sequence) * 100\n",
        "    }\n",
        "    return analysis\n",
        "\n",
        "# Analyze all sequences and write results\n",
        "with open('sequence_analysis.txt', 'w') as output_file:\n",
        "    output_file.write(\"Sequence Analysis Results\\n\")\n",
        "    output_file.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "    for header, sequence in sequences.items():\n",
        "        analysis = analyze_sequence(sequence)\n",
        "        output_file.write(f\"Sequence: {header}\\n\")\n",
        "        output_file.write(f\"Length: {analysis['length']} amino acids\\n\")\n",
        "        output_file.write(f\"Amino acid composition:\\n\")\n",
        "        output_file.write(f\"  A: {analysis['A_count']}\\n\")\n",
        "        output_file.write(f\"  T: {analysis['T_count']}\\n\")\n",
        "        output_file.write(f\"  G: {analysis['G_count']}\\n\")\n",
        "        output_file.write(f\"  C: {analysis['C_count']}\\n\")\n",
        "        output_file.write(f\"GC Content: {analysis['gc_content']:.2f}%\\n\")\n",
        "        output_file.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "print(\"Analysis complete! Results written to sequence_analysis.txt\")\n",
        "\n",
        "# Display the results\n",
        "with open('sequence_analysis.txt', 'r') as file:\n",
        "    print(file.read())"
      ],
      "metadata": {
        "id": "y24ZgiRxrNoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ì„¹ì…˜ 2.** CSV íŒŒì¼ ì²˜ë¦¬ (ì‹¤í—˜ ë°ì´í„°)\n",
        "**2.1 ê¸°ë³¸ CSV ì‘ì—…**\n",
        "\n",
        "CSVëŠ” **Comma Separated Values**ì˜ ì•½ìì…ë‹ˆë‹¤. í‘œ í˜•ì‹ ë°ì´í„°(ìˆ«ì ë° í…ìŠ¤íŠ¸)ë¥¼ êµ¬ì¡°í™”ëœ ë°©ì‹ìœ¼ë¡œ ì €ì¥í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ê°„ë‹¨í•œ ì¼ë°˜ í…ìŠ¤íŠ¸ íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. íŒŒì¼ì˜ ê° ì¤„ì€ ë°ì´í„° ë ˆì½”ë“œë¥¼ ë‚˜íƒ€ë‚´ë©°, ê° ë ˆì½”ë“œëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í•˜ë‚˜ ì´ìƒì˜ í•„ë“œë¡œ êµ¬ì„±ë©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "YzvhQsUJrVH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dummy CSV file\n",
        "csv_data = \"\"\"Name,Age,City\n",
        "Alice,30,New York\n",
        "Bob,24,London\n",
        "Charlie,35,Paris\n",
        "David,28,\"San Francisco\"\n",
        "\"\"\"\n",
        "with open(\"people.csv\", \"w\") as f:\n",
        "    f.write(csv_data.strip())\n",
        "\n",
        "print(\"Created 'people.csv' for demonstration.\")"
      ],
      "metadata": {
        "id": "IPJxDZtdoWfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the above CSV file\n",
        "import csv\n",
        "\n",
        "print(\"\\nReading 'people.csv' with csv.reader:\")\n",
        "with open('people.csv', 'r', newline='') as file:\n",
        "    csv_reader = csv.reader(file)\n",
        "    header = next(csv_reader) # Read the header row\n",
        "    print(f\"Header: {header}\")\n",
        "\n",
        "    for row in csv_reader:\n",
        "        print(f\"Row: {row}\")\n",
        "        # You can access elements by index, e.g., row[0] for Name, row[1] for Age\n",
        "        # print(f\"Name: {row[0]}, Age: {row[1]}, City: {row[2]}\")"
      ],
      "metadata": {
        "id": "ktg69-2nowY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Create sample experimental data\n",
        "experimental_data = [\n",
        "    ['Sample_ID', 'Treatment', 'Concentration', 'Growth_Rate', 'Viability'],\n",
        "    ['S001', 'Control', 0, 2.3, 98.5],\n",
        "    ['S002', 'Drug_A', 10, 1.8, 85.2],\n",
        "    ['S003', 'Drug_A', 50, 1.2, 72.1],\n",
        "    ['S004', 'Drug_A', 100, 0.8, 45.3],\n",
        "    ['S005', 'Drug_B', 10, 2.1, 92.1],\n",
        "    ['S006', 'Drug_B', 50, 1.5, 78.9],\n",
        "    ['S007', 'Drug_B', 100, 1.0, 55.7],\n",
        "    ['S008', 'Control', 0, 2.4, 97.8]\n",
        "]\n",
        "\n",
        "# Write to CSV file\n",
        "with open('experimental_data.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(experimental_data)\n",
        "\n",
        "print(\"Experimental data CSV created!\")"
      ],
      "metadata": {
        "id": "fsxhn2IerV6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and display CSV data\n",
        "with open('experimental_data.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    print(\"Experimental Data:\")\n",
        "    for row in reader:\n",
        "        print('\\t'.join(row))"
      ],
      "metadata": {
        "id": "UIW_DQhNf9Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2 DictReaderë¥¼ ì‚¬ìš©í•˜ì—¬ CSV ì‘ì—…í•˜ê¸°**"
      ],
      "metadata": {
        "id": "6iByDVX9gBBX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`csv.DictReader` í´ë˜ìŠ¤ëŠ” CSV íŒŒì¼ì„ ë‹¤ë£° ë•Œ, íŠ¹íˆ ë°ì´í„°ì— ëª…í™•í•œ í—¤ë” í–‰ì´ ìˆì„ ë•Œ ë§¤ìš° ê°•ë ¥í•˜ê³  ê¶Œì¥ë˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. `row[0]`, `row[1]`ê³¼ ê°™ì´ ì¸ë±ìŠ¤ ë²ˆí˜¸ë¥¼ ê¸°ì–µí•´ì•¼ í•˜ëŠ” ë¬¸ìì—´ ëª©ë¡ì„ ì œê³µí•˜ëŠ” ëŒ€ì‹ , `DictReader`ëŠ” ê° í–‰ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ì œê³µí•©ë‹ˆë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì½”ë“œê°€ í›¨ì”¬ ë” ì½ê¸° ì‰¬ì›Œì§€ê³  ì—´ ìˆœì„œê°€ ë³€ê²½ë  ê²½ìš° ì˜¤ë¥˜ê°€ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ ì¤„ì–´ë“­ë‹ˆë‹¤.\n",
        "\n",
        "### `DictReader`ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ \n",
        "\n",
        "* **ê°€ë…ì„±:** ì¸ë±ìŠ¤(ì˜ˆ: `row[0]`) ëŒ€ì‹  ì—´ ì´ë¦„(ì˜ˆ: `row['Name']`)ìœ¼ë¡œ ë°ì´í„°ì— ì•¡ì„¸ìŠ¤í•©ë‹ˆë‹¤.\n",
        "* **ìœ ì§€ ê´€ë¦¬ì„±:** ì½”ë“œê°€ ë” ê²¬ê³ í•´ì§‘ë‹ˆë‹¤. CSV íŒŒì¼ì—ì„œ ì—´ì´ ì¬ì •ë ¬ë˜ë”ë¼ë„ ì—´ ì´ë¦„ì´ ë™ì¼í•˜ê²Œ ìœ ì§€ë˜ëŠ” í•œ ì½”ë“œê°€ ì†ìƒë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
        "* **í¸ì˜ì„±:** ë°ì´í„°ë¥¼ í‚¤-ê°’ ìŒ í˜•ì‹ìœ¼ë¡œ ì§ì ‘ ì œê³µí•˜ë¯€ë¡œ ì‘ì—…í•˜ê¸°ê°€ ë” ì‰¬ìš´ ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.\n",
        "\n",
        "### 1. `csv.DictReader`ì˜ ê¸°ë³¸ ì‚¬ìš©ë²•\n",
        "\n",
        "`DictReader`ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì—´ë¦° íŒŒì¼ ê°ì²´ë¥¼ ì „ë‹¬í•˜ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤. ì²« ë²ˆì§¸ í–‰ì„ ìë™ìœ¼ë¡œ í—¤ë”ë¡œ ì½ê³  í•´ë‹¹ ê°’ì„ í›„ì† í–‰ì˜ ë”•ì…”ë„ˆë¦¬ í‚¤ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "l2NF5d_dpZTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**experimental_data**ë¥¼ ì „ë‹¬í•´ ë³´ê² ìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "4bP8UOMqqJOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV as dictionaries\n",
        "with open('experimental_data.csv', 'r') as csvfile:\n",
        "    reader = csv.DictReader(csvfile)\n",
        "\n",
        "    print(\"Data as dictionaries:\")\n",
        "    for row in reader:\n",
        "        print(f\"Sample {row['Sample_ID']}: {row['Treatment']} treatment\")\n",
        "        print(f\"  Concentration: {row['Concentration']} Î¼M\")\n",
        "        print(f\"  Growth Rate: {row['Growth_Rate']} /hr\")\n",
        "        print(f\"  Viability: {row['Viability']}%\")\n",
        "        print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "Zctu0kKygFWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3 ë°ì´í„° ë¶„ì„ ë° í•„í„°ë§** <br>\n",
        "ë°ì´í„° ë¶„ì„ì€ ìœ ìš©í•œ ì •ë³´ë¥¼ ë°œê²¬í•˜ê³ , ê²°ë¡ ì„ ì•Œë¦¬ê³ , ì˜ì‚¬ ê²°ì •ì„ ì§€ì›í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ ë°ì´í„°ë¥¼ ê²€ì‚¬, ì •ë¦¬, ë³€í™˜ ë° ëª¨ë¸ë§í•˜ëŠ” ê²ƒì„ í¬í•¨í•©ë‹ˆë‹¤. ë°ì´í„° í•„í„°ë§ì€ íŠ¹ì • ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ” ë°ì´í„°ì˜ íŠ¹ì • í•˜ìœ„ ì§‘í•©ì„ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ì´ ì‘ì—…ì˜ í•µì‹¬ ë¶€ë¶„ì…ë‹ˆë‹¤.\n",
        "\n",
        "### 1. ê¸°ë³¸ í•„í„°ë§ ë° ë¶„ì„ (íŒŒì´ì¬ ë‚´ì¥ ê¸°ëŠ¥ ì‚¬ìš©)\n",
        "\n",
        "ì „ë¬¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ê¸° ì „ì—, íŠ¹íˆ `csv.DictReader`ë¥¼ ì‚¬ìš©í•˜ì—¬ CSVë¥¼ êµ¬ë¬¸ ë¶„ì„í•œ ê²½ìš° í‘œì¤€ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ì™€ ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ë³¸ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë°©ë²•ì„ ì´í•´í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "EsTAtfCegGX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure people.csv exists\n",
        "csv_data = \"\"\"Name,Age,City,Occupation,Salary\n",
        "Alice,30,New York,Engineer,75000\n",
        "Bob,24,London,Designer,60000\n",
        "Charlie,35,Paris,Manager,90000\n",
        "David,28,\"San Francisco\",Engineer,80000\n",
        "Eve,22,Berlin,Analyst,55000\n",
        "Frank,40,Tokyo,Manager,100000\n",
        "Grace,29,Sydney,Designer,62000\n",
        "\"\"\"\n",
        "with open(\"people.csv\", \"w\") as f:\n",
        "    f.write(csv_data.strip())\n",
        "\n",
        "print(\"Ensured 'people.csv' for demonstration.\")\n",
        "\n",
        "import csv\n",
        "\n",
        "# Load the data into a list of dictionaries\n",
        "people_data = []\n",
        "with open('people.csv', 'r', newline='') as file:\n",
        "    csv_dict_reader = csv.DictReader(file)\n",
        "    for row in csv_dict_reader:\n",
        "        # Convert numeric values from string to appropriate types\n",
        "        try:\n",
        "            row['Age'] = int(row['Age'])\n",
        "            row['Salary'] = int(row['Salary'])\n",
        "        except ValueError:\n",
        "            print(f\"Warning: Could not convert numeric values in row: {row}\")\n",
        "            continue # Skip row if conversion fails\n",
        "        people_data.append(row)\n",
        "\n",
        "print(\"\\nLoaded data (first 3 records):\")\n",
        "for i, person in enumerate(people_data[:3]):\n",
        "    print(person)\n",
        "    if i == 2: break"
      ],
      "metadata": {
        "id": "uFx1HatVrI5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze experimental data\n",
        "def analyze_experimental_data(filename):\n",
        "    \"\"\"Analyze experimental data from CSV file\"\"\"\n",
        "    treatments = {}\n",
        "\n",
        "    with open(filename, 'r') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "\n",
        "        for row in reader:\n",
        "            treatment = row['Treatment']\n",
        "            concentration = float(row['Concentration'])\n",
        "            growth_rate = float(row['Growth_Rate'])\n",
        "            viability = float(row['Viability'])\n",
        "\n",
        "            if treatment not in treatments:\n",
        "                treatments[treatment] = {\n",
        "                    'concentrations': [],\n",
        "                    'growth_rates': [],\n",
        "                    'viabilities': []\n",
        "                }\n",
        "\n",
        "            treatments[treatment]['concentrations'].append(concentration)\n",
        "            treatments[treatment]['growth_rates'].append(growth_rate)\n",
        "            treatments[treatment]['viabilities'].append(viability)\n",
        "\n",
        "    return treatments\n",
        "\n",
        "# Analyze the data\n",
        "results = analyze_experimental_data('experimental_data.csv')\n",
        "\n",
        "# Calculate statistics\n",
        "for treatment, data in results.items():\n",
        "    print(f\"\\nTreatment: {treatment}\")\n",
        "    print(f\"Number of samples: {len(data['growth_rates'])}\")\n",
        "    print(f\"Average growth rate: {sum(data['growth_rates'])/len(data['growth_rates']):.2f} /hr\")\n",
        "    print(f\"Average viability: {sum(data['viabilities'])/len(data['viabilities']):.2f}%\")\n",
        "    print(f\"Concentration range: {min(data['concentrations'])}-{max(data['concentrations'])} Î¼M\")"
      ],
      "metadata": {
        "id": "IGGSdFxvgKoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4 ì²˜ë¦¬ëœ ë°ì´í„° ì“°ê¸°**"
      ],
      "metadata": {
        "id": "vudF34_VgPZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process and write summary data\n",
        "summary_data = []\n",
        "summary_data.append(['Treatment', 'Sample_Count', 'Avg_Growth_Rate', 'Avg_Viability', 'Max_Concentration'])\n",
        "\n",
        "for treatment, data in results.items():\n",
        "    avg_growth = sum(data['growth_rates']) / len(data['growth_rates'])\n",
        "    avg_viability = sum(data['viabilities']) / len(data['viabilities'])\n",
        "    max_concentration = max(data['concentrations'])\n",
        "    sample_count = len(data['growth_rates'])\n",
        "\n",
        "    summary_data.append([treatment, sample_count, f\"{avg_growth:.2f}\", f\"{avg_viability:.2f}\", max_concentration])\n",
        "\n",
        "# Write summary to new CSV\n",
        "with open('treatment_summary.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(summary_data)\n",
        "\n",
        "print(\"Summary data written to treatment_summary.csv\")\n",
        "\n",
        "# Display summary\n",
        "with open('treatment_summary.csv', 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile)\n",
        "    print(\"\\nTreatment Summary:\")\n",
        "    for row in reader:\n",
        "        print('\\t'.join(row))"
      ],
      "metadata": {
        "id": "6Hz3DpsigSMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ì„¹ì…˜ 3.** ìƒë¬¼í•™ì  ë°ì´í„°ì…‹ì„ ìœ„í•œ ê¸°ë³¸ íŒŒì¼ ì‘ì—…\n",
        "ìƒë¬¼í•™ì  ë°ì´í„°ì…‹ì€ ì¢…ì¢… ë‹¤ì–‘í•œ íŒŒì¼ í˜•ì‹(ì˜ˆ: FASTA, FASTQ, BAM, VCF, CSV, TSV)ìœ¼ë¡œ ì œê³µë˜ë©° ë§¤ìš° í´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ íŒŒì¼ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ê²ƒì€ ìƒë¬¼ ì •ë³´í•™ ì›Œí¬í”Œë¡œì— ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ ì„¹ì…˜ì—ì„œëŠ” ìƒë¬¼í•™ì  ë°ì´í„°ì—ì„œ í”íˆ ì ‘í•˜ëŠ” ì¼ë°˜ì ì¸ ì‘ì—…ì— ì´ˆì ì„ ë§ì¶° íŒŒì´ì¬ì˜ ê¸°ë³¸ì ì¸ íŒŒì¼ ì‘ì—…ì„ ë‹¤ë£¹ë‹ˆë‹¤.<br>\n",
        "**3.1 íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…**\n",
        "\n",
        "`os` `glob` ë° `shutil` ëª¨ë“ˆì€ íŒŒì¼ **ì¡´ì¬** í™•ì¸, íŒŒì¼ ë° ë””ë ‰í„°ë¦¬ **ì´ë™**, **ë³µì‚¬**, **ì‚­ì œ**ì™€ ê°™ì€ íŒŒì¼ ì‹œìŠ¤í…œê³¼ ìƒí˜¸ ì‘ìš©í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "Fw54vdDEgZLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Create a directory structure for biological data\n",
        "directories = ['data', 'data/sequences', 'data/experiments', 'results']\n",
        "\n",
        "for directory in directories:\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        print(f\"Created directory: {directory}\")\n",
        "\n",
        "# Move files to appropriate directories\n",
        "import shutil\n",
        "\n",
        "# Move sequence files\n",
        "if os.path.exists('sample_sequences.fasta'):\n",
        "    shutil.move('sample_sequences.fasta', 'data/sequences/')\n",
        "    print(\"Moved FASTA file to sequences directory\")\n",
        "\n",
        "if os.path.exists('sample_dna.txt'):\n",
        "    shutil.move('sample_dna.txt', 'data/sequences/')\n",
        "    print(\"Moved DNA file to sequences directory\")\n",
        "\n",
        "# Move experimental data\n",
        "if os.path.exists('experimental_data.csv'):\n",
        "    shutil.move('experimental_data.csv', 'data/experiments/')\n",
        "    print(\"Moved experimental data to experiments directory\")\n",
        "\n",
        "# Move results\n",
        "if os.path.exists('sequence_analysis.txt'):\n",
        "    shutil.move('sequence_analysis.txt', 'results/')\n",
        "    print(\"Moved analysis results to results directory\")\n",
        "\n",
        "if os.path.exists('treatment_summary.csv'):\n",
        "    shutil.move('treatment_summary.csv', 'results/')\n",
        "    print(\"Moved summary to results directory\")"
      ],
      "metadata": {
        "id": "CehFBg8ZgvMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 íŒŒì¼ ì¼ê´„ ì²˜ë¦¬**"
      ],
      "metadata": {
        "id": "Ro0w7JfFgzXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create multiple sequence files for batch processing\n",
        "sample_sequences = {\n",
        "    'gene1.fasta': '>gene1\\nATCGATCGATCGATCG\\nGCTAGCTAGCTAGCTA',\n",
        "    'gene2.fasta': '>gene2\\nTTAAGGCCTTAAGGCC\\nCGATCGATCGATCGAT',\n",
        "    'gene3.fasta': '>gene3\\nGGCCTTAAGGCCTTAA\\nATCGATCGATCGATCG'\n",
        "}\n",
        "\n",
        "# Write sample files\n",
        "for filename, content in sample_sequences.items():\n",
        "    with open(f'data/sequences/{filename}', 'w') as file:\n",
        "        file.write(content)\n",
        "\n",
        "print(\"Created sample sequence files for batch processing\")"
      ],
      "metadata": {
        "id": "NBsIUndZgzuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch process all FASTA files\n",
        "def batch_process_fasta_files(directory):\n",
        "    \"\"\"Process all FASTA files in a directory\"\"\"\n",
        "    fasta_files = glob.glob(os.path.join(directory, '*.fasta'))\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for filepath in fasta_files:\n",
        "        filename = os.path.basename(filepath)\n",
        "        print(f\"Processing: {filename}\")\n",
        "\n",
        "        sequences = parse_fasta(filepath)\n",
        "\n",
        "        for header, sequence in sequences.items():\n",
        "            analysis = analyze_sequence(sequence)\n",
        "            results[filename] = {\n",
        "                'header': header,\n",
        "                'analysis': analysis\n",
        "            }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Process all FASTA files\n",
        "batch_results = batch_process_fasta_files('data/sequences/')\n",
        "\n",
        "# Write batch results\n",
        "with open('results/batch_analysis.txt', 'w') as output_file:\n",
        "    output_file.write(\"Batch Analysis Results\\n\")\n",
        "    output_file.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "    for filename, data in batch_results.items():\n",
        "        output_file.write(f\"File: {filename}\\n\")\n",
        "        output_file.write(f\"Sequence: {data['header']}\\n\")\n",
        "        analysis = data['analysis']\n",
        "        output_file.write(f\"Length: {analysis['length']} bp\\n\")\n",
        "        output_file.write(f\"GC Content: {analysis['gc_content']:.2f}%\\n\")\n",
        "        output_file.write(\"-\" * 30 + \"\\n\")\n",
        "\n",
        "print(\"Batch analysis complete!\")"
      ],
      "metadata": {
        "id": "voN_s5g1g72A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.3 ì˜¤ë¥˜ ì²˜ë¦¬ ë° íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬**"
      ],
      "metadata": {
        "id": "nqLpKtG3g_f3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_file_reader(filename):\n",
        "    \"\"\"Safely read a file with error handling\"\"\"\n",
        "    try:\n",
        "        with open(filename, 'r') as file:\n",
        "            content = file.read()\n",
        "            return content\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{filename}' not found!\")\n",
        "        return None\n",
        "    except PermissionError:\n",
        "        print(f\"Error: Permission denied for file '{filename}'!\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file '{filename}': {e}\")\n",
        "        return None\n",
        "\n",
        "# Test error handling\n",
        "print(\"Testing error handling:\")\n",
        "content = safe_file_reader('nonexistent_file.txt')\n",
        "print(f\"Content: {content}\")\n",
        "\n",
        "# Test with existing file\n",
        "content = safe_file_reader('results/batch_analysis.txt')\n",
        "if content:\n",
        "    print(f\"Successfully read file. Length: {len(content)} characters\")"
      ],
      "metadata": {
        "id": "LcJUxr7nhBxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.4 íŒŒì¼ ì •ë³´ ë° í†µê³„**"
      ],
      "metadata": {
        "id": "lOkDlHpZhGM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_info(filepath):\n",
        "    \"\"\"Get information about a file\"\"\"\n",
        "    try:\n",
        "        stats = os.stat(filepath)\n",
        "        return {\n",
        "            'size': stats.st_size,\n",
        "            'modified': stats.st_mtime,\n",
        "            'exists': True\n",
        "        }\n",
        "    except:\n",
        "        return {'exists': False}\n",
        "\n",
        "# Get information about all files in results directory\n",
        "results_files = glob.glob('results/*')\n",
        "\n",
        "print(\"File Information:\")\n",
        "print(\"=\" * 50)\n",
        "for filepath in results_files:\n",
        "    info = get_file_info(filepath)\n",
        "    if info['exists']:\n",
        "        filename = os.path.basename(filepath)\n",
        "        print(f\"File: {filename}\")\n",
        "        print(f\"  Size: {info['size']} bytes\")\n",
        "        print(f\"  Modified: {info['modified']}\")\n",
        "        print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "b9cPU82XhKSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. ì‹¤ìŠµ ë¬¸ì œ\n",
        "**ì—°ìŠµ ë¬¸ì œ 1: ìœ ì „ì ë°œí˜„ ë°ì´í„° ì²˜ë¦¬**"
      ],
      "metadata": {
        "id": "s_S05L4ehN9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample gene expression data\n",
        "gene_expression_data = [\n",
        "    ['Gene_ID', 'Gene_Name', 'Control_1', 'Control_2', 'Treatment_1', 'Treatment_2'],\n",
        "    ['G001', 'GAPDH', 1000, 1050, 980, 1020],\n",
        "    ['G002', 'ACTB', 800, 820, 750, 780],\n",
        "    ['G003', 'TP53', 200, 180, 450, 420],\n",
        "    ['G004', 'BRCA1', 150, 160, 300, 280],\n",
        "    ['G005', 'MYC', 300, 280, 150, 170]\n",
        "]\n",
        "\n",
        "with open('data/experiments/gene_expression.csv', 'w', newline='') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerows(gene_expression_data)\n",
        "\n",
        "print(\"Gene expression data created!\")"
      ],
      "metadata": {
        "id": "qEhnccbkhVTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ê³¼ì œ:** ê° ìœ ì „ìì˜ ë°œí˜„ ë³€í™”ëŸ‰ì„ ê³„ì‚°í•˜ê³  ìœ ì˜í•˜ê²Œ ë³€í™”í•œ ìœ ì „ìë¥¼ ì‹ë³„í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤."
      ],
      "metadata": {
        "id": "ZfufjCdyhdY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ì—°ìŠµ ë¬¸ì œ 2: ì‹œí€€ìŠ¤ ë°ì´í„°ì˜ í’ˆì§ˆ ê´€ë¦¬**"
      ],
      "metadata": {
        "id": "roe_cnIRhjgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sequence with quality issues\n",
        "problematic_sequences = \"\"\">seq_with_N\n",
        "ATCGATCGATCNNNGATCGATCG\n",
        ">short_seq\n",
        "ATCG\n",
        ">seq_with_gaps\n",
        "ATCGATCG---ATCGATCG\n",
        ">normal_seq\n",
        "ATCGATCGATCGATCGATCG\"\"\"\n",
        "\n",
        "with open('data/sequences/quality_check.fasta', 'w') as file:\n",
        "    file.write(problematic_sequences)\n",
        "\n",
        "print(\"Quality check sequences created!\")"
      ],
      "metadata": {
        "id": "8EnKE6oXhc2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ê³¼ì œ:** ë¬¸ì œê°€ ìˆëŠ” ì‹œí€€ìŠ¤ë¥¼ ì‹ë³„í•˜ê³  ë³´ê³ í•˜ëŠ” í’ˆì§ˆ ê´€ë¦¬ í•¨ìˆ˜ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤."
      ],
      "metadata": {
        "id": "KLtoNEnNhzVz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ìš”ì•½**<br>\n",
        "ì´ ì¥ì—ì„œ ë°°ìš´ ë‚´ìš©:\n",
        "\n",
        "**1. í…ìŠ¤íŠ¸ íŒŒì¼ ì‘ì—…:** FASTAì™€ ê°™ì€ ìƒë¬¼í•™ì  ë°ì´í„° í˜•ì‹ì„ í¬í•¨í•œ í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸° ë° ì“°ê¸° ë°©ë²•<br>\n",
        "**2. CSV íŒŒì¼ ì²˜ë¦¬:** íŒŒì´ì¬ì˜ csv ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì—¬ CSV í˜•ì‹ì˜ ì‹¤í—˜ ë°ì´í„° ì‘ì—…<br>\n",
        "**3. íŒŒì¼ ì‹œìŠ¤í…œ ì‘ì—…:** ë””ë ‰í† ë¦¬ ë° ì¼ê´„ ì²˜ë¦¬ë¡œ ìƒë¬¼í•™ì  ë°ì´í„°ì…‹ êµ¬ì„±<br>\n",
        "**4. ì˜¤ë¥˜ ì²˜ë¦¬:** ì ì ˆí•œ ì˜¤ë¥˜ ì²˜ë¦¬ë¡œ ê°•ë ¥í•œ íŒŒì¼ ì‘ì—… êµ¬í˜„<br>\n",
        "**5. ëª¨ë²” ì‚¬ë¡€:** ìƒë¬¼í•™ì  ë°ì´í„° ë¶„ì„ì—ì„œ íŒŒì¼ ì²˜ë¦¬ë¥¼ ìœ„í•œ íŒŒì´ì¬ ê·œì¹™ ì¤€ìˆ˜<br>\n",
        "\n",
        "ì´ëŸ¬í•œ ê¸°ìˆ ì€ ìƒë¬¼í•™ì  ë°ì´í„°ì…‹ìœ¼ë¡œ ì‘ì—…í•˜ê¸° ìœ„í•œ ê¸°ì´ˆë¥¼ í˜•ì„±í•˜ë©° ë” ê³ ê¸‰ ë°ì´í„° ë¶„ì„ ì‘ì—…ì— í•„ìˆ˜ì ì…ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "srDAnB17ijAW"
      }
    }
  ]
}
